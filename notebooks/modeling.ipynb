{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1c1bd4-b74b-4639-98e1-80a96f048be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anip/miniconda3/envs/sds/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "root_path = os.path.dirname(current_path)\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "# lib\n",
    "from src.dataset import DocumentDataset\n",
    "from src.utils import draw_boxes, apply_ocr\n",
    "\n",
    "# nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import LayoutLMTokenizer, LayoutLMForSequenceClassification\n",
    "from transformers import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3b331-e8af-4336-86c9-6c4e7a97ff6e",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8736eb-dcca-4b34-8e98-abd283a94a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(root_path, 'data')\n",
    "\n",
    "# load the dataset\n",
    "dataset = DocumentDataset(data_path=data_path)\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb52a2-612b-496a-84fb-db0769f57c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b947407a-5322-4b18-9c50-645edcc1e8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LayoutLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LayoutLMForSequenceClassification(\n",
       "  (layoutlm): LayoutLMModel(\n",
       "    (embeddings): LayoutLMEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (x_position_embeddings): Embedding(1024, 768)\n",
       "      (y_position_embeddings): Embedding(1024, 768)\n",
       "      (h_position_embeddings): Embedding(1024, 768)\n",
       "      (w_position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LayoutLMEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LayoutLMLayer(\n",
       "          (attention): LayoutLMAttention(\n",
       "            (self): LayoutLMSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LayoutLMSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LayoutLMIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LayoutLMOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LayoutLMPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LayoutLMForSequenceClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=len(dataset.labels))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674279f-1459-44f0-8dd3-e54a44f35a22",
   "metadata": {},
   "source": [
    "## Define the train, val and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02e2f3e-b889-4a01-8f45-0f9fa59a5076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split_ratio = 0.8\n",
    "val_split_ratio = 0.1\n",
    "test_split_ration = 0.1\n",
    "\n",
    "train_size = int(train_split_ratio * len(dataset))\n",
    "val_size = int(val_split_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb735ff-bc67-40e1-a7a3-6e63675be956",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88c744-c45f-49d4-8388-a62864150197",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50ae50d-bd52-48c4-bdec-2d14e7eb2df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd022a3-cdee-4381-938f-67765e83bc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [24:13<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.533275840759743\n",
      "Average train accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:57<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average val loss: 0.408884329829365\n",
      "Average val accuracy: 0.848\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [24:57<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.23069822494010442\n",
      "Average train accuracy: 0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [03:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average val loss: 0.34862392212636767\n",
      "Average val accuracy: 0.888\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [25:50<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.13496689462405628\n",
      "Average train accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [03:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average val loss: 0.3545875901784748\n",
      "Average val accuracy: 0.908\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [25:39<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.08260223338217475\n",
      "Average train accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [03:03<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average val loss: 0.4173163246400654\n",
      "Average val accuracy: 0.88\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [24:43<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.0609215815901116\n",
      "Average train accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:56<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average val loss: 0.39413693897938357\n",
      "Average val accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    # train mode\n",
    "    model.train()\n",
    "\n",
    "    running_loss_train = 0.0\n",
    "    correct_train = 0\n",
    "    for step, batch in enumerate(tqdm.tqdm(train_dataloader)):\n",
    "        \n",
    "        # convert the boxes to tensor\n",
    "        bboxes = torch.stack([torch.stack(bbox) for bbox in batch['bbox']]).to(device)\n",
    "        bboxes = bboxes.reshape(bboxes.shape[2], bboxes.shape[0], bboxes.shape[1])\n",
    "        #print(f\"bboxes: {bboxes.shape}\")\n",
    "\n",
    "        # input ids\n",
    "        input_ids = torch.stack(batch['input_ids']).to(device)\n",
    "        input_ids = input_ids.reshape(input_ids.shape[1], input_ids.shape[0])\n",
    "        #print(f\"input_ids: {input_ids.shape}\")        \n",
    "\n",
    "        # attention mask\n",
    "        attention_mask = torch.stack(batch['attention_mask']).to(device)\n",
    "        attention_mask = attention_mask.reshape(attention_mask.shape[1], attention_mask.shape[0])\n",
    "        #print(f\"attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "        # token type ids\n",
    "        token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
    "        token_type_ids = token_type_ids.reshape(token_type_ids.shape[1], token_type_ids.shape[0])\n",
    "        #print(f\"token_type_ids: {token_type_ids.shape}\")\n",
    "\n",
    "        # labels\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            bbox=bboxes,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # update loss and accuracy\n",
    "        loss = outputs.loss\n",
    "        running_loss_train += loss.item()\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        correct_train += (predictions == labels).sum().item()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = running_loss_train / len(train_dataloader)\n",
    "    avg_train_acc = correct_train / len(train_dataloader)\n",
    "    print(f'Average train loss: {avg_train_loss}')\n",
    "    print(f'Average train accuracy: {avg_train_acc}')\n",
    "\n",
    "    # validation mode\n",
    "    model.eval()\n",
    "\n",
    "    running_loss_val = 0.0\n",
    "    correct_val = 0\n",
    "    for step, batch in enumerate(tqdm.tqdm(val_dataloader)):\n",
    "            \n",
    "        # convert the boxes to tensor\n",
    "        bboxes = torch.stack([torch.stack(bbox) for bbox in batch['bbox']]).to(device)\n",
    "        bboxes = bboxes.reshape(bboxes.shape[2], bboxes.shape[0], bboxes.shape[1])\n",
    "        #print(f\"bboxes: {bboxes.shape}\")\n",
    "\n",
    "        # input ids\n",
    "        input_ids = torch.stack(batch['input_ids']).to(device)\n",
    "        input_ids = input_ids.reshape(input_ids.shape[1], input_ids.shape[0])\n",
    "        #print(f\"input_ids: {input_ids.shape}\")        \n",
    "\n",
    "        # attention mask\n",
    "        attention_mask = torch.stack(batch['attention_mask']).to(device)\n",
    "        attention_mask = attention_mask.reshape(attention_mask.shape[1], attention_mask.shape[0])\n",
    "        #print(f\"attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "        # token type ids\n",
    "        token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
    "        token_type_ids = token_type_ids.reshape(token_type_ids.shape[1], token_type_ids.shape[0])\n",
    "        #print(f\"token_type_ids: {token_type_ids.shape}\")\n",
    "\n",
    "        # labels\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            bbox=bboxes,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # update loss and accuracy\n",
    "        loss = outputs.loss\n",
    "        running_loss_val += loss.item()\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        correct_val += (predictions == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = running_loss_val / len(val_dataloader)\n",
    "    avg_val_acc = correct_val / len(val_dataloader)\n",
    "    print(f'Average val loss: {avg_val_loss}')\n",
    "    print(f'Average val accuracy: {avg_val_acc}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57025b2-6a45-45fe-b246-b15ac1bad4e5",
   "metadata": {},
   "source": [
    "## Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4f1534-75b6-44fb-a8c5-d2aa365a68de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(root_path, 'models', 'layoutlm-model')\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa03270-2c0e-4ae2-964b-98cb6de1e889",
   "metadata": {},
   "source": [
    "## Load the model from disk\n",
    "- Comment if you are doing training and testing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52430fbb-7412-4261-bc5f-c8bedf9d63f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = LayoutLMForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7064c-3ae1-451e-b538-4e3f4e5957b7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89de43f7-dc12-4d5e-87ed-2bdedafd9651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [03:01<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.2526314825930167\n",
      "Average test accuracy: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test mode\n",
    "model.eval()\n",
    "\n",
    "running_loss_test = 0.0\n",
    "correct_test = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for step, batch in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "            \n",
    "    # convert the boxes to tensor\n",
    "    bboxes = torch.stack([torch.stack(bbox) for bbox in batch['bbox']]).to(device)\n",
    "    bboxes = bboxes.reshape(bboxes.shape[2], bboxes.shape[0], bboxes.shape[1])\n",
    "    #print(f\"bboxes: {bboxes.shape}\")\n",
    "\n",
    "    # input ids\n",
    "    input_ids = torch.stack(batch['input_ids']).to(device)\n",
    "    input_ids = input_ids.reshape(input_ids.shape[1], input_ids.shape[0])\n",
    "    #print(f\"input_ids: {input_ids.shape}\")        \n",
    "\n",
    "    # attention mask\n",
    "    attention_mask = torch.stack(batch['attention_mask']).to(device)\n",
    "    attention_mask = attention_mask.reshape(attention_mask.shape[1], attention_mask.shape[0])\n",
    "    #print(f\"attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "    # token type ids\n",
    "    token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
    "    token_type_ids = token_type_ids.reshape(token_type_ids.shape[1], token_type_ids.shape[0])\n",
    "    #print(f\"token_type_ids: {token_type_ids.shape}\")\n",
    "\n",
    "    # labels\n",
    "    labels = batch['label'].to(device)\n",
    "\n",
    "    # forward\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        bbox=bboxes,\n",
    "        token_type_ids=token_type_ids,\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "    # update loss and accuracy\n",
    "    loss = outputs.loss\n",
    "    running_loss_test += loss.item()\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    correct_test += (predictions == labels).sum().item()\n",
    "\n",
    "    # update y_true and y_pred\n",
    "    y_true.extend(labels.tolist())\n",
    "    y_pred.extend(predictions.tolist())\n",
    "\n",
    "\n",
    "avg_test_loss = running_loss_test / len(test_dataloader)\n",
    "avg_test_acc = correct_test / len(test_dataloader)\n",
    "print(f'Average test loss: {avg_test_loss}')\n",
    "print(f'Average test accuracy: {avg_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b8edc-e7bf-459d-b645-6d484a63e618",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d9c8f56-eb35-46e6-ba1d-67f362ef288c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e927b1-3844-4540-8de0-89c827e331b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9807692307692307,\n",
       "  'recall': 0.9272727272727272,\n",
       "  'f1-score': 0.9532710280373831,\n",
       "  'support': 55},\n",
       " '1': {'precision': 0.859375,\n",
       "  'recall': 0.9482758620689655,\n",
       "  'f1-score': 0.9016393442622951,\n",
       "  'support': 58},\n",
       " '2': {'precision': 0.9148936170212766,\n",
       "  'recall': 0.9772727272727273,\n",
       "  'f1-score': 0.945054945054945,\n",
       "  'support': 44},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.9574468085106383,\n",
       "  'f1-score': 0.9782608695652174,\n",
       "  'support': 47},\n",
       " '4': {'precision': 1.0,\n",
       "  'recall': 0.9130434782608695,\n",
       "  'f1-score': 0.9545454545454545,\n",
       "  'support': 46},\n",
       " 'accuracy': 0.944,\n",
       " 'macro avg': {'precision': 0.9510075695581015,\n",
       "  'recall': 0.9446623206771856,\n",
       "  'f1-score': 0.946554328293059,\n",
       "  'support': 250},\n",
       " 'weighted avg': {'precision': 0.9481655073649754,\n",
       "  'recall': 0.944,\n",
       "  'f1-score': 0.9447790314813715,\n",
       "  'support': 250}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a455b8e7-9eb1-410d-9a40-09c762ed6c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  4,  0,  0,  0],\n",
       "       [ 1, 55,  2,  0,  0],\n",
       "       [ 0,  1, 43,  0,  0],\n",
       "       [ 0,  2,  0, 45,  0],\n",
       "       [ 0,  2,  2,  0, 42]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734d499-e349-47d1-9ad3-8d2042d05cd3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Train Accuracy: 0.982\n",
    "- Validation Accuracy: 0.9\n",
    "- Test Accuracy: 0.944\n",
    "- Average Precision: 0.951\n",
    "- Average Recall: 0.944\n",
    "- Average F1-Score: 0.946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf79cfc-ba87-4afb-8d4c-2648e3ce6aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
